"""
analysis_factorization_test.py

Test the validity of the factorization approximation

    I(q)  ?=  N * P(q) * S(q)

for house-of-cards disc systems generated by hoc_structural_model.py.

Definitions used:
-----------------
We compute, for each configuration and each q-direction:

  A_full(q) = sum_j F_j(q_vec, n_j) * exp(i q_vec · r_j)
  A_com(q)  = sum_j exp(i q_vec · r_j)

Then we define:

  I_full(q)  = < |A_full(q)|^2 >_dirs,configs
  S_cm(q)    = < |A_com(q)|^2 / N >_dirs,configs
  P_eff(q)   = < (1/N) sum_j |F_j(q_vec, n_j)|^2 >_dirs,configs

and the factorized approximation:

  I_fact(q) = N * P_eff(q) * S_cm(q)

We then look at the ratio:

  R(q) = I_full(q) / I_fact(q)

Additionally, we measure timing:
  - time_full : time spent computing full amplitudes I_full
  - time_ps   : time spent computing P_eff and S_cm
"""

import os
import glob
import math
import time
import numpy as np
import matplotlib.pyplot as plt

from scipy.special import j1          # Bessel J1
from tqdm import tqdm


# ============================================================
# USER PARAMETERS
# ============================================================

# Directory and pattern where hoc_structural_model.py saved coords
DATA_DIR = "hoc_output_prob0.8_random_n1000"               # adjust as needed
FILE_PATTERN = "hoc_structure_coords_*.csv"

# Disc geometry (must match generator)
RADIUS = 25.0                         # nm
THICKNESS = 1.0                       # nm
DELTA_RHO = 1.0                       # scattering length density contrast

# q-grid
Q_MIN = 0.005                         # nm^-1
Q_MAX = 0.5                           # nm^-1
N_Q = 80
LOG_Q = True

# Number of random q-directions per q for orientational average
N_Q_DIRECTIONS = 24
RNG_SEED = 12345

# Output files
OUT_CSV = "factorization_test_iq_ps.csv"
OUT_PLOT = "factorization_test_plot_prob0.5.png"
OUT_TIMING_CSV = "factorization_timing.csv"


# ============================================================
# Utilities
# ============================================================

def info(msg: str) -> None:
    """Safe logging that does not break tqdm."""
    tqdm.write(msg)


def random_unit_vectors(n, rng):
    """
    Generate n random unit vectors uniformly on the sphere.
    """
    z = rng.uniform(-1.0, 1.0, size=n)
    phi = rng.uniform(0.0, 2.0*np.pi, size=n)
    r_xy = np.sqrt(np.clip(1.0 - z*z, 0.0, None))
    x = r_xy * np.cos(phi)
    y = r_xy * np.sin(phi)
    return np.column_stack([x, y, z])


def load_configuration(path):
    """
    Load x,y,z,nx,ny,nz from CSV.

    Returns
    -------
    positions : (N,3)
    normals   : (N,3)
    """
    data = np.loadtxt(path, delimiter=",", skiprows=1)
    positions = data[:, :3]
    normals = data[:, 3:]
    normals /= (np.linalg.norm(normals, axis=1, keepdims=True) + 1e-12)
    return positions, normals


def disc_amplitude(normals, q_vec,
                   R=RADIUS, T=THICKNESS, dr=DELTA_RHO):
    """
    Cylinder-disc scattering amplitude for each particle:

      F = Δρ [ 2 sin(q_par T/2) / q_par ] [ 2πR J1(q_perp R) / q_perp ]

    normals : (N,3)
    q_vec   : (3,)
    returns : (N,) complex128
    """
    q2 = np.dot(q_vec, q_vec)
    q_par = normals @ q_vec               # (N,)
    q_perp_sq = np.clip(q2 - q_par**2, 0.0, None)
    q_perp = np.sqrt(q_perp_sq)

    eps = 1e-12

    # thickness factor
    zfac = np.where(
        np.abs(q_par) < eps,
        T,
        2.0 * np.sin(q_par * T / 2.0) / q_par
    )

    # radial factor
    arg = q_perp * R
    rfac = np.where(
        np.abs(arg) < eps,
        np.pi * R**2,
        2.0 * np.pi * R * j1(arg) / (q_perp + eps)
    )

    F = dr * zfac * rfac
    return F.astype(np.complex128)


# ============================================================
# Core computation
# ============================================================

def compute_factorization_test(positions,
                               normals,
                               q_values,
                               n_dirs=N_Q_DIRECTIONS,
                               rng=None,
                               pbar=None):
    """
    For a single configuration, compute contributions to I_full, P_eff, S_cm.

    Returns per-q arrays:
      I_full_contrib(q), P_eff_contrib(q), S_cm_contrib(q),
    and timing:
      time_full (seconds), time_ps (seconds)
    """
    if rng is None:
        rng = np.random.default_rng()

    N = positions.shape[0]
    Nq = q_values.size

    I_full = np.zeros(Nq, dtype=float)
    P_eff = np.zeros(Nq, dtype=float)
    S_cm = np.zeros(Nq, dtype=float)

    # timing accumulators
    time_full = 0.0
    time_ps = 0.0

    # random q-directions, shared across q
    q_dirs = random_unit_vectors(n_dirs, rng)  # (n_dirs,3)

    for iq, q in enumerate(q_values):
        I_sum = 0.0
        P_sum = 0.0
        S_sum = 0.0

        for d in range(n_dirs):
            q_vec = q * q_dirs[d]
            phase = positions @ q_vec      # (N,)

            # --- full amplitude timing ---
            t0 = time.perf_counter()
            F_j = disc_amplitude(normals, q_vec)   # (N,)
            A_full = (F_j * np.exp(1j * phase)).sum()
            t1 = time.perf_counter()
            time_full += (t1 - t0)

            # --- P(q), S(q) (COM + |F|^2) timing ---
            t2 = time.perf_counter()
            A_com = np.exp(1j * phase).sum()
            I_sum += (A_full.conjugate() * A_full).real

            # S(q) based purely on COM:
            S_sum += (A_com.conjugate() * A_com).real / N

            # effective P(q): single-particle contribution
            #   P_eff_dir(q) = (1/N) sum_j |F_j(q_vec,n_j)|^2
            P_sum += np.mean(np.abs(F_j)**2)
            t3 = time.perf_counter()
            time_ps += (t3 - t2)

        I_full[iq] = I_sum / n_dirs
        S_cm[iq] = S_sum / n_dirs
        P_eff[iq] = P_sum / n_dirs

        if pbar is not None:
            pbar.update(1)

    return I_full, P_eff, S_cm, time_full, time_ps


# ============================================================
# Main
# ============================================================

def main():
    pattern = os.path.join(DATA_DIR, FILE_PATTERN)
    paths = sorted(glob.glob(pattern))

    if not paths:
        print(f"[ERROR] No configuration files found at {pattern}")
        return

    print("[INFO] Using coordinate files:")
    for p in paths:
        print("   ", p)

    # q-grid
    if LOG_Q:
        q_values = np.logspace(np.log10(Q_MIN), np.log10(Q_MAX), N_Q)
    else:
        q_values = np.linspace(Q_MIN, Q_MAX, N_Q)

    print(f"[INFO] q-grid: {N_Q} points from {q_values[0]:.4e} to {q_values[-1]:.4e} nm^-1")
    print(f"[INFO] Using {N_Q_DIRECTIONS} q-directions per q")

    rng = np.random.default_rng(RNG_SEED)

    total_steps = len(paths) * len(q_values)
    pbar = tqdm(total=total_steps, desc="Total progress", leave=True)

    I_full_all = []
    P_eff_all = []
    S_cm_all = []

    # timing accumulators over all configs
    total_time_full = 0.0
    total_time_ps = 0.0

    overall_t0 = time.perf_counter()

    for idx, path in enumerate(paths):
        info(f"[INFO] Processing config {idx+1}/{len(paths)}: {os.path.basename(path)}")
        positions, normals = load_configuration(path)

        I_full, P_eff, S_cm, t_full, t_ps = compute_factorization_test(
            positions,
            normals,
            q_values,
            n_dirs=N_Q_DIRECTIONS,
            rng=rng,
            pbar=pbar
        )

        I_full_all.append(I_full)
        P_eff_all.append(P_eff)
        S_cm_all.append(S_cm)

        total_time_full += t_full
        total_time_ps += t_ps

    overall_t1 = time.perf_counter()
    total_time_all = overall_t1 - overall_t0

    pbar.close()

    # average over configs
    I_full_avg = np.mean(I_full_all, axis=0)
    P_eff_avg = np.mean(P_eff_all, axis=0)
    S_cm_avg = np.mean(S_cm_all, axis=0)

    # get N from first config
    first_positions, _ = load_configuration(paths[0])
    N_part = first_positions.shape[0]
    info(f"[INFO] Number of particles (first config): {N_part}")

    # factorized I(q)
    I_fact = N_part * P_eff_avg * S_cm_avg

    # ratio
    ratio = I_full_avg / (I_fact + 1e-20)

    # save CSV with I(q), P(q), S(q), ratio
    out = np.column_stack([
        q_values,
        I_full_avg,
        I_fact,
        P_eff_avg,
        S_cm_avg,
        ratio
    ])
    header = "q, I_full, I_fact, P_eff, S_cm, ratio_I_full_over_I_fact"
    np.savetxt(OUT_CSV, out, delimiter=",", header=header, comments="")
    print(f"[INFO] Saved {OUT_CSV}")

    # save timing CSV
    timing_arr = np.array([
        ["I_full_full_amplitude", f"{total_time_full:.6f}"],
        ["P_S_components", f"{total_time_ps:.6f}"],
        ["total_wall_time", f"{total_time_all:.6f}"],
    ], dtype=object)
    np.savetxt(
        OUT_TIMING_CSV,
        timing_arr,
        fmt="%s",
        delimiter=",",
        header="method,time_seconds",
        comments=""
    )
    print(f"[INFO] Saved timing info to {OUT_TIMING_CSV}")
    print(f"[INFO]   time_full (sum over all configs): {total_time_full:.3f} s")
    print(f"[INFO]   time_P_S  (sum over all configs): {total_time_ps:.3f} s")
    print(f"[INFO]   total wall time                : {total_time_all:.3f} s")

    # plotting: I_full vs I_fact and ratio
    fig, axes = plt.subplots(2, 1, figsize=(7, 9))

    # Top: I_full vs I_fact (normalized)
    I_full_norm = I_full_avg / (I_full_avg.max() + 1e-20)
    I_fact_norm = I_fact / (I_fact.max() + 1e-20)

    axes[0].loglog(q_values, I_full_norm, label="I_full(q) (full amplitude)")
    axes[0].loglog(q_values, I_fact_norm, "--", label="I_fact(q) = N P_eff S_cm")
    axes[0].set_xlabel("q (nm$^{-1}$)")
    axes[0].set_ylabel("I(q) (normalized)")
    axes[0].set_title("Full vs factorized intensity (normalized)")
    axes[0].grid(True, which="both", ls=":")
    axes[0].legend()

    # Bottom: ratio
    axes[1].semilogx(q_values, ratio, "-o", ms=3)
    axes[1].axhline(1.0, color="k", lw=1, ls="--")
    axes[1].set_xlabel("q (nm$^{-1}$)")
    axes[1].set_ylabel("I_full / I_fact")
    axes[1].set_title("Ratio I_full(q) / [N P_eff(q) S_cm(q)]")
    axes[1].grid(True, which="both", ls=":")

    plt.tight_layout()
    plt.savefig(OUT_PLOT, dpi=200)
    plt.close()
    print(f"[INFO] Saved plot to {OUT_PLOT}")
    print("[INFO] Done.")


if __name__ == "__main__":
    main()
